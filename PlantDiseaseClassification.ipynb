{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPThExPJUB7msmpkW2wXdr+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitneverdebugs/Plant-Disease-Classification-/blob/main/PlantDiseaseClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM2c9Yw2ShTi"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json file"
      ],
      "metadata": {
        "id": "hMnh3nIjSs_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json  # Set permissions for the API key\n"
      ],
      "metadata": {
        "id": "KFqvwMR0SlY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d vipoooool/new-plant-diseases-dataset"
      ],
      "metadata": {
        "id": "Hz2GZGaDSm15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip new-plant-diseases-dataset.zip -d /content/"
      ],
      "metadata": {
        "id": "OurBPIC1SqlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Path to the unzipped dataset\n",
        "dataset_path = '/content/New Plant Diseases Dataset(Augmented)/'\n",
        "\n",
        "# List to hold image paths and labels\n",
        "data = []\n",
        "\n",
        "# Loop through each category (folder)\n",
        "for label in os.listdir(dataset_path):\n",
        "    label_path = os.path.join(dataset_path, label)\n",
        "\n",
        "    # Loop through each image in the category\n",
        "    if os.path.isdir(label_path):\n",
        "        for image_file in os.listdir(label_path):\n",
        "            # Append the image path and label to the data list\n",
        "            data.append([os.path.join(label_path, image_file), label])\n",
        "\n",
        "# Create a DataFrame from the data list\n",
        "df = pd.DataFrame(data, columns=['image_path', 'label'])\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "NRV_o4P1S_Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset = \"/kaggle/input/new-plant-diseases-dataset\"\n",
        "train_data = \"/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\n",
        "valid_data = \"/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\"\n",
        "test_data = \"/content/test/test\"\n",
        "\n",
        "dataset_dir, dataset_last = os.path.split(dataset)\n",
        "train_dir, train_last = os.path.split(train_data)\n",
        "valid_dir, valid_last = os.path.split(valid_data)\n",
        "test_dir, test_last = os.path.split(test_data)\n",
        "\n",
        "print(\"Dataset path split:\", dataset_dir, dataset_last)\n",
        "print(\"Train data path split:\", train_dir, train_last)\n",
        "print(\"Validation data path split:\", valid_dir, valid_last)\n",
        "print(\"Test data path split:\", test_dir, test_last)"
      ],
      "metadata": {
        "id": "Wlnl-xVJTSBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diseases=os.listdir(train_data)\n",
        "print(diseases)"
      ],
      "metadata": {
        "id": "eLScpdpUUwHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of classes : \",len(diseases))"
      ],
      "metadata": {
        "id": "rAMq5wC7UwbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nums_train={}\n",
        "nums_valid={}\n",
        "for disease in diseases:\n",
        "    nums_train[disease]=len(os.listdir(train_data+'/'+disease))\n",
        "    nums_valid[disease]=len(os.listdir(valid_data+'/'+disease))\n",
        "image_class_count_train=pd.DataFrame(nums_train.values(),index=nums_train.keys(),columns=['No. of images'])\n",
        "print('Training data images count per class : ',)\n",
        "print(image_class_count_train)"
      ],
      "metadata": {
        "id": "6pCaVZtDikbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_class_count_valid=pd.DataFrame(nums_valid.values(),index=nums_valid.keys(),columns=['No. of images'])\n",
        "print('Validation data images count per class : ',)\n",
        "print(image_class_count_valid)"
      ],
      "metadata": {
        "id": "XQQJ_uQaipQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "id": "xLLgVKY9i98o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os                       # for working with files\n",
        "import numpy as np              # for numerical computationss\n",
        "import pandas as pd             # for working with dataframes\n",
        "import seaborn as sns           # for working with maps\n",
        "import torch                    # Pytorch module\n",
        "import matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\n",
        "import torch.nn as nn           # for creating  neural networks\n",
        "from torch.utils.data import DataLoader # for dataloaders\n",
        "from PIL import Image           # for checking images\n",
        "import torch.nn.functional as F # for functions for calculating loss\n",
        "import torchvision.transforms as transforms   # for transforming images into tensors\n",
        "from torchvision.utils import make_grid       # for data checking\n",
        "from torchvision.datasets import ImageFolder  # for working with classes and images\n",
        "from torchsummary import summary              # for getting the summary of our model\n",
        "import tensorflow as ts\n",
        "from  tensorflow import keras\n",
        "import itertools\n",
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "ZFLz2lHHjAwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.title(\"Training data images count per class\",fontsize=38)\n",
        "plt.xlabel('Number of images', fontsize=35)\n",
        "plt.ylabel('Classes', fontsize=35)\n",
        "\n",
        "keys=list(nums_train.keys())\n",
        "vals=list(nums_train.values())\n",
        "sns.barplot(y=keys,x=vals)"
      ],
      "metadata": {
        "id": "8BaxKshzivtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.title(\"Validation data images count per class\",fontsize=38)\n",
        "plt.xlabel('Number of images', fontsize=35)\n",
        "plt.ylabel('Classes', fontsize=35)\n",
        "\n",
        "keys=list(nums_valid.keys())\n",
        "vals=list(nums_valid.values())\n",
        "sns.barplot(y=keys,x=vals)"
      ],
      "metadata": {
        "id": "7lXPlG-Riyui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_train=0\n",
        "for value in nums_train.values():\n",
        "    total_train+=value\n",
        "print(\"Total number of images for training : \", total_train)"
      ],
      "metadata": {
        "id": "Vks3VmYjjXpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_valid=0\n",
        "for value in nums_valid.values():\n",
        "    total_valid+=value\n",
        "print(\"Total number of images for validation : \", total_valid)"
      ],
      "metadata": {
        "id": "kv7r1przjZtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plants_unique=[]\n",
        "diseases_unique=[]\n",
        "for i in diseases:\n",
        "    if(i.split('__'))[0] not in plants_unique:\n",
        "        plants_unique.append(i.split('__')[0])\n",
        "    if(i.split('___'))[1] != 'healthy':\n",
        "        diseases_unique.append(i.split('___')[1])"
      ],
      "metadata": {
        "id": "dCRkuA1sjbaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Plants : ', plants_unique)\n",
        "print('-'*100)\n",
        "print('Number of plants : ', len(plants_unique))"
      ],
      "metadata": {
        "id": "gL_CDb46jhjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Diseases : ', diseases_unique)\n",
        "print('-'*100)\n",
        "print('Number of diseases : ', len(diseases_unique))"
      ],
      "metadata": {
        "id": "imQASg5ljnnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rescale=keras.layers.Rescaling(scale=1.0/255)"
      ],
      "metadata": {
        "id": "EOXDAzKwjpH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data =keras.utils.image_dataset_from_directory(train_data , image_size=(256, 256))\n",
        "validation_data = keras.utils.image_dataset_from_directory(valid_data, image_size=(256, 256))"
      ],
      "metadata": {
        "id": "jUs25Ki0j4Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = training_data.map(lambda image, label: (rescale(image), label))\n",
        "valid_gen = validation_data.map(lambda image, label: (rescale(image), label))"
      ],
      "metadata": {
        "id": "Ge4Wq4qdkA8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(38, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BllyghL7kalf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_gen, validation_data=valid_gen, epochs=15)"
      ],
      "metadata": {
        "id": "2R7Bb7MHkk19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(history.history['loss'],label=\"Train Loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Validation Loss\")\n",
        "plt.xlim(0, 15)\n",
        "plt.ylim(0.0,2.0)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "VzbE2H0ooknw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Train and Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(history.history['accuracy'], label=\"Train Accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label=\"Validation Accuracy\")\n",
        "plt.xlim(0, 15)\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "pIYg1NCM0c_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "predictions = []\n",
        "for x,y in valid_gen:\n",
        "    labels.append(list(y.numpy()))\n",
        "    predictions.append(ts.argmax(model.predict(x),1).numpy())"
      ],
      "metadata": {
        "id": "n7UVtAK60fV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = list(itertools.chain.from_iterable(predictions))\n",
        "labels = list(itertools.chain.from_iterable(labels))"
      ],
      "metadata": {
        "id": "iwU2_bQo0i0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Accuracy  : {:.2f} %\".format(history.history['accuracy'][-1]*100))\n",
        "print(\"Test Accuracy   : {:.2f} %\".format(accuracy_score(labels, predictions) * 100))\n",
        "print(\"Precision Score : {:.2f} %\".format(precision_score(labels, predictions, average='micro') * 100))\n",
        "print(\"Recall Score    : {:.2f} %\".format(recall_score(labels, predictions, average='micro') * 100))"
      ],
      "metadata": {
        "id": "Vy7Bpre206MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize= (20,5))\n",
        "cm = confusion_matrix(labels, predictions)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(1,39)))\n",
        "fig, ax = plt.subplots(figsize=(12,12))\n",
        "disp.plot(ax=ax,colorbar= False,cmap = 'YlGnBu')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kZzqjQpH078u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_array = np.array(labels)\n",
        "predictions_array = np.array(predictions)\n",
        "\n",
        "# Perform one-hot encoding on the labels and predictions\n",
        "num_classes = 38  # Replace with the actual number of classes\n",
        "labels_one_hot = label_binarize(labels_array, classes=range(num_classes))\n",
        "predictions_one_hot = label_binarize(predictions_array, classes=range(num_classes))\n",
        "\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "plt.figure(figsize= (38,38))\n",
        "for i in range(num_classes):\n",
        "    precision[i], recall[i], _ = precision_recall_curve(labels_one_hot[:, i], predictions_one_hot[:, i])\n",
        "    plt.plot(recall[i], precision[i], label=f'Class {i}')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1BuytVl00-Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Li = ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n",
        "      'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy',\n",
        "      'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
        "      'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy',\n",
        "      'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight',\n",
        "      'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch',\n",
        "      'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight',\n",
        "      'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
        "      'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n",
        "# predicting an image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "directory=\"/content/test/test\"\n",
        "files = [os.path.join(directory,p) for p in sorted(os.listdir(directory))]\n",
        "for i in range(0,33):\n",
        "    image_path = files[i]\n",
        "    new_img =keras.utils.load_img(image_path, target_size=(256, 256))\n",
        "    img = keras.utils.img_to_array(new_img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img/255\n",
        "    prediction = model.predict(img)\n",
        "    probabilty = prediction.flatten()\n",
        "    max_prob = probabilty.max()\n",
        "    index=prediction.argmax(axis=-1)[0]\n",
        "    class_name = Li[index]\n",
        "    #ploting image with predicted class name\n",
        "    plt.figure(figsize = (4,4))\n",
        "    plt.imshow(new_img)\n",
        "    plt.axis('off')\n",
        "    plt.title(class_name+\" \"+ str(max_prob)[0:4]+\"%\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "WAplUK3w1BpD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}